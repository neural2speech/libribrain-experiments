data:
  datasets:
    train:
      - libribrain_speech_simplified:
          data_path: '<DATA_PATH>'
          preprocessing_str: 'bads+headpos+sss+notch+bp+ds'
          standardize: true
          tmin: 0.0
          tmax: 2.5
          exclude_run_keys: [['0', '11', 'Sherlock1', '2'], ['0', '12', 'Sherlock1', '2']]
          preload_files: false
          stride: 60
          meg_augment:
            time_mask:
              num: 2          # how many masks per window
              T:  180         # max width [samples]
            bandstop_mask:
              bands:          # Hz ranges at 250 Hz SR
                - [4, 7]      # theta
                - [8, 13]     # alpha
                - [14, 31]    # beta
                - [32, 100]   # gamma
                - [60, 124]   # high-gamma (clipped to Nyquist)
              order: 4
              p: 0.40

    val:
      - libribrain_speech_simplified:
          data_path: '<DATA_PATH>'
          standardize: true
          tmin: 0.0
          tmax: 2.5
          include_run_keys: [['0', '11', 'Sherlock1', '2']]
          preload_files: false
          stride: 1  # sample-level score reporting
    test:
      - libribrain_speech_simplified:
          data_path: '<DATA_PATH>'
          standardize: true
          tmin: 0.0
          tmax: 2.5
          include_run_keys: [['0', '12', 'Sherlock1', '2']]
          preload_files: false
          stride: 1  # sample-level score reporting
  dataloader:
    batch_size: 256
    num_workers: 4
  general:
    inMemory: False


model:
  - conformer:
      in_dropout: 0.1

      # Small
      hidden_size: 144        # Encoder Dim (pick 256 or 512 for M/L)
      ffn_dim: 576            # 4x hidden_size
      num_layers: 16
      num_heads: 4

      # Medium
      # hidden_size: 256
      # ffn_dim: 1024
      # num_layers: 16
      # num_heads: 4

      # Large
      # hidden_size: 512
      # ffn_dim: 2048
      # num_layers: 17
      # num_heads: 8

      # General parameters
      depthwise_conv_kernel_size: 31
      seq_len: 625            # length of window (samples)
      input_dim: 306          # sensors
      use_preproj: conv1d     # leave on unless hidden_size == 306
      num_classes: 1          # speech %

loss:
  name: bce_with_smoothing
  config:
    smoothing: 0.1
    pos_weight: 1.0


optimizer:
  name: adamw
  config:
    lr: 0.0001
    weight_decay: 0.05

trainer:
  max_epochs: 100
  early_stopping:
    monitor: val_f1_macro
    min_delta: 0.00
    patience: 10
    verbose: true
    mode: max

general:
  wandb: True
  output_path: '<RESULTS_PATH>/final-speech-results'
  checkpoint_path: '<CHECKPOINTS_PATH>/final-speech-results'
  seed: 42
  eval_checkpoint: best
  best_model_metrics: val_f1_macro
  single_logit: true
